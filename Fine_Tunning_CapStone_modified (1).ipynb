{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8de0d971",
      "metadata": {
        "id": "8de0d971"
      },
      "source": [
        "# **Install needed Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f6b29e-17c4-4263-a2ca-4d5fed398979",
      "metadata": {
        "id": "25f6b29e-17c4-4263-a2ca-4d5fed398979"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets peft accelerate bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1229d38c",
      "metadata": {
        "id": "1229d38c"
      },
      "outputs": [],
      "source": [
        "pip install nltk rouge-score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf0ed3f",
      "metadata": {
        "id": "4bf0ed3f"
      },
      "source": [
        "# Cell 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fee35c0",
      "metadata": {
        "id": "2fee35c0"
      },
      "source": [
        "# Cell 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rWgIoQbUvdDH",
      "metadata": {
        "id": "rWgIoQbUvdDH"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed1e8f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"....\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a85c724-351a-48dd-80d8-cef451520aaf",
      "metadata": {
        "collapsed": true,
        "id": "7a85c724-351a-48dd-80d8-cef451520aaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 46.88ba/s]\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 106.21ba/s]\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/Yasser18/QA_clean/commit/7875a0e1eb42c302c5c6ec969762bfeaf639e338', commit_message='Upload dataset', commit_description='', oid='7875a0e1eb42c302c5c6ec969762bfeaf639e338', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Yasser18/QA_clean', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Yasser18/QA_clean'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "\n",
        "with open(\"output_unique_5000.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "formatted = []\n",
        "for item in raw_data:\n",
        "    question = item.get(\"question\", \"\").strip()\n",
        "    answer = item.get(\"answer\", \"\")\n",
        "    if isinstance(answer, list):\n",
        "        answer = \"\\n\".join(answer)\n",
        "    elif isinstance(answer, dict):\n",
        "        answer = \"\\n\".join(f\"{k}: {', '.join(v) if isinstance(v, list) else v}\" for k, v in answer.items())\n",
        "    formatted.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "ds = Dataset.from_list(formatted)\n",
        "ds_dict = ds.train_test_split(test_size=0.1)\n",
        "\n",
        "ds_dict.push_to_hub(\"Yasser18/QA_clean\", private=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f27013",
      "metadata": {
        "id": "47f27013"
      },
      "source": [
        "# Cell 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb233f97",
      "metadata": {
        "id": "fb233f97"
      },
      "source": [
        "# Cell 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9972c2-c030-44db-9863-8f40ca894b2a",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "cce81c3250cd4bdabab72105e23d3715",
            "c691e3e8eb2746c58bb59110ef9ac18c",
            "590e524253934b55b07c8a7901c9f7a4",
            "478cc17493e44c53b49b118dd564a747",
            "56bd052e24074834a06cf2c0c04c2727",
            "f3046fc68b30432ca178884a4c312115",
            "bb2fa35fa5c74b20846964cc267c657d"
          ]
        },
        "id": "8d9972c2-c030-44db-9863-8f40ca894b2a",
        "outputId": "7808706d-ca3b-466f-b898-1bf89f7a2fa1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cce81c3250cd4bdabab72105e23d3715",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c691e3e8eb2746c58bb59110ef9ac18c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "590e524253934b55b07c8a7901c9f7a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "478cc17493e44c53b49b118dd564a747",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56bd052e24074834a06cf2c0c04c2727",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3046fc68b30432ca178884a4c312115",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb2fa35fa5c74b20846964cc267c657d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
        "import torch\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
        "\n",
        "# BitsAndBytes 4bit quantization setup\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",  # safer than hardcoding {“”: 0}\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "\n",
        "# Tokenizer setup\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2faba94f",
      "metadata": {
        "id": "2faba94f"
      },
      "source": [
        "# Cell 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34248551-adda-4284-bc67-9967513ed4ba",
      "metadata": {
        "id": "34248551-adda-4284-bc67-9967513ed4ba"
      },
      "outputs": [],
      "source": [
        "# Preprocess function for question-answer format\n",
        "def preprocess(example):\n",
        "    prompt = f\"### Question:\\n{example['question']}\\n\\n### Answer:\\n{example['answer']}\"\n",
        "\n",
        "    tokenized = tokenizer(\n",
        "        prompt,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
        "    tokenized[\"labels\"][tokenized[\"attention_mask\"] == 0] = -100  # mask out padding tokens\n",
        "\n",
        "    return {key: val.squeeze(0) for key, val in tokenized.items()}\n",
        "\n",
        "# Apply preprocessing to dataset\n",
        "tokenized_dataset = dataset.map(preprocess)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df4527b0",
      "metadata": {
        "id": "df4527b0"
      },
      "source": [
        "# Cell 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f347ef6-900e-4b98-a9c5-c24d4036d945",
      "metadata": {
        "id": "6f347ef6-900e-4b98-a9c5-c24d4036d945"
      },
      "outputs": [],
      "source": [
        "def tokenize(example):\n",
        "    return tokenizer(\n",
        "        f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "tokenized_dataset = dataset.map(preprocess)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67ae1928",
      "metadata": {
        "id": "67ae1928"
      },
      "source": [
        "# Cell 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787cca94-5759-4b8d-bffe-a7190336412e",
      "metadata": {
        "id": "787cca94-5759-4b8d-bffe-a7190336412e"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_steps=50,\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    learning_rate=2e-4\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6bb1d9",
      "metadata": {
        "id": "2e6bb1d9"
      },
      "source": [
        "# Cell 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fdb8086",
      "metadata": {
        "id": "3fdb8086"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"./final_model\")\n",
        "tokenizer.save_pretrained(\"./final_model\")\n",
        "print(\"Model saved to ./final_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228d640d",
      "metadata": {
        "id": "228d640d"
      },
      "source": [
        "# Cell 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8e3f6d-5d8a-4dc6-926d-108efbadf1ae",
      "metadata": {
        "id": "8b8e3f6d-5d8a-4dc6-926d-108efbadf1ae",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"./final_model\", tokenizer=\"./final_model\", device=0)\n",
        "\n",
        "prompt = \"What should I know about using the APS soldering tool?\"\n",
        "generated = pipe(prompt, max_new_tokens=200, do_sample=True, temperature=0.7)\n",
        "print(\"Generated Response:\\n\", generated[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b63a6de",
      "metadata": {
        "id": "2b63a6de"
      },
      "source": [
        "# Cell 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b85ef3c-c7a8-455f-970f-cf79c56f02ff",
      "metadata": {
        "id": "6b85ef3c-c7a8-455f-970f-cf79c56f02ff"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41c7eb2a",
      "metadata": {
        "id": "41c7eb2a"
      },
      "source": [
        "# Cell 10 - Bleu & Rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40d4391-3392-40d0-b9c5-b0036e061351",
      "metadata": {
        "id": "f40d4391-3392-40d0-b9c5-b0036e061351"
      },
      "outputs": [],
      "source": [
        "# Cell 10 – Evaluation with BLEU and ROUGE\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "reference = \"You should follow the APS soldering tool safety steps and perform maintenance every 6 months.\"\n",
        "candidate = generated[0]['generated_text']\n",
        "\n",
        "# BLEU Score (with smoothing)\n",
        "smoothie = SmoothingFunction().method4\n",
        "bleu_score = sentence_bleu([reference.split()], candidate.split(), smoothing_function=smoothie)\n",
        "print(\"BLEU Score with smoothing:\", bleu_score)\n",
        "\n",
        "# ROUGE Score\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(reference, candidate)\n",
        "\n",
        "print(\"\\nROUGE Scores:\")\n",
        "for k, v in scores.items():\n",
        "    print(f\"{k}: Precision={v.precision:.4f}, Recall={v.recall:.4f}, F1={v.fmeasure:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k6coIkZ-0Ab2",
      "metadata": {
        "id": "k6coIkZ-0Ab2"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"final_model\", 'zip', \"./final_model\")\n",
        "print(\"Zipped model as final_model.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YoNA_tj562R6",
      "metadata": {
        "id": "YoNA_tj562R6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"final_model.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CK5p8SS565UN",
      "metadata": {
        "id": "CK5p8SS565UN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AI_Enginnring",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
